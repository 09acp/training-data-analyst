{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Serving embeddings </h1>\n",
    "\n",
    "This notebook illustrates how to:\n",
    "<ol>\n",
    "<li> Create a custom embedding as part of a regression/classification model\n",
    "<li> Representing categorical variables in different ways\n",
    "<li> Math with feature columns\n",
    "<li> Serve out the embedding, as well as the original model's predictions\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating dataset\n",
    "\n",
    "The problem is to estimate demand for bicycles at different rental stations in New York City.  The necessary data is in BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "#standardsql\n",
    "WITH bicycle_rentals AS (\n",
    "  SELECT\n",
    "    COUNT(starttime) as num_trips,\n",
    "    EXTRACT(DATE from starttime) as trip_date,\n",
    "    MAX(EXTRACT(DAYOFWEEK from starttime)) as day_of_week,\n",
    "    start_station_id\n",
    "  FROM `bigquery-public-data.new_york.citibike_trips`\n",
    "  GROUP BY trip_date, start_station_id\n",
    "),\n",
    "\n",
    "rainy_days AS\n",
    "(\n",
    "SELECT\n",
    "  date,\n",
    "  (MAX(prcp) > 5) AS rainy\n",
    "FROM (\n",
    "  SELECT\n",
    "    wx.date AS date,\n",
    "    IF (wx.element = 'PRCP', wx.value/10, NULL) AS prcp\n",
    "  FROM\n",
    "    `bigquery-public-data.ghcn_d.ghcnd_2016` AS wx\n",
    "  WHERE\n",
    "    wx.id = 'USW00094728'\n",
    ")\n",
    "GROUP BY\n",
    "  date\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  num_trips,\n",
    "  day_of_week,\n",
    "  start_station_id,\n",
    "  rainy\n",
    "FROM bicycle_rentals AS bk\n",
    "JOIN rainy_days AS wx\n",
    "ON wx.date = bk.trip_date\n",
    "\"\"\"\n",
    "import google.datalab.bigquery as bq\n",
    "df = bq.Query(query).execute().result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>rainy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47422</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38106</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109413</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3049</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120722</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_trips  day_of_week  start_station_id  rainy\n",
       "47422          44            3               408  False\n",
       "19297          22            2               266   True\n",
       "38106          37            3               270  False\n",
       "109413         19            6              3049   True\n",
       "120722         18            7               364  False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the dataframe to make it easier to split into train/eval later\n",
    "df = df.sample(frac=1.0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature engineering\n",
    "Let's build a model to predict the number of trips that start at each station, given that we know the day of the week and whether it is a rainy day.\n",
    "\n",
    "Inputs to the model:\n",
    "* day of week (integerized, since it is 1-7)\n",
    "* station id (hash buckets, since we don't know full vocabulary. The dataset has about 650 unique values. we'll use a much larger hash bucket size, but then embed it into a lower dimension)\n",
    "* rainy (true/false)\n",
    "\n",
    "Label:\n",
    "* num_trips\n",
    "\n",
    "By embedding the station id into just 2 dimensions, we will also get to learn which stations are like each other, at least in the context of rainy-day-rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Change data type\n",
    "\n",
    "Let's change the Pandas data types to more efficient (for TensorFlow) forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_trips           int64\n",
       "day_of_week         int64\n",
       "start_station_id    int64\n",
       "rainy                bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_trips           float32\n",
       "day_of_week           int32\n",
       "start_station_id      int32\n",
       "rainy                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = df.astype({'num_trips': np.float32, 'day_of_week': np.int32, 'start_station_id': np.int32, 'rainy': str})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Scale the label to make it easier to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['num_trips'] = df['num_trips'] / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 104148 training examples and 26037 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "num_train = (int) (len(df) * 0.8)\n",
    "train_df = df.iloc[:num_train]\n",
    "eval_df  = df.iloc[num_train:]\n",
    "print(\"Split into {} training examples and {} evaluation examples\".format(len(train_df), len(eval_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>rainy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47422</th>\n",
       "      <td>0.044</td>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>0.022</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38106</th>\n",
       "      <td>0.037</td>\n",
       "      <td>3</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109413</th>\n",
       "      <td>0.019</td>\n",
       "      <td>6</td>\n",
       "      <td>3049</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120722</th>\n",
       "      <td>0.018</td>\n",
       "      <td>7</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_trips  day_of_week  start_station_id  rainy\n",
       "47422       0.044            3               408  False\n",
       "19297       0.022            2               266   True\n",
       "38106       0.037            3               270  False\n",
       "109413      0.019            6              3049   True\n",
       "120722      0.018            7               364  False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Creating an Estimator model </h2>\n",
    "\n",
    "Pretty minimal, but it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def make_input_fn(indf, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    indf,\n",
    "    indf['num_trips'],\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True)\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      'day_of_week': tf.placeholder(tf.int32, [None]),\n",
    "      'start_station_id': tf.placeholder(tf.int32, [None]),\n",
    "      'rainy': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "  \n",
    "def train_and_evaluate(output_dir, nsteps):\n",
    "  station_embed = tf.feature_column.embedding_column(\n",
    "      tf.feature_column.categorical_column_with_hash_bucket('start_station_id', 5000, tf.int32), 2)\n",
    "  feature_cols = [\n",
    "    tf.feature_column.categorical_column_with_identity('day_of_week', num_buckets = 8),\n",
    "    station_embed,\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('rainy', ['false', 'true'])\n",
    "  ]\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = feature_cols)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = make_input_fn(train_df, None),\n",
    "                       max_steps = nsteps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = make_input_fn(eval_df, 1),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "  \n",
    "import shutil\n",
    "OUTDIR='./model_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True)\n",
    "train_and_evaluate(OUTDIR, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predict using the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.json\n"
     ]
    }
   ],
   "source": [
    "%writefile test.json\n",
    "{\"day_of_week\": 3, \"start_station_id\": 384, \"rainy\": \"false\"}\n",
    "{\"day_of_week\": 4, \"start_station_id\": 384, \"rainy\": \"true\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "[0.07941299676895142]\n",
      "[0.08212406188249588]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-07-10 13:51:46.348062: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "EXPORTDIR=./model_trained/export/exporter/\n",
    "MODELDIR=$(ls $EXPORTDIR | tail -1)\n",
    "gcloud ml-engine local predict --model-dir=${EXPORTDIR}/${MODELDIR} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Serving out the embedding also\n",
    "\n",
    "To serve out the embedding, we need to use a model function (a custom estimator) so that we have access to output_alternates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7df06edd90>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './model_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 10 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.4781056, step = 1\n",
      "INFO:tensorflow:global_step/sec: 251.718\n",
      "INFO:tensorflow:loss = 0.005082916, step = 101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.001\n",
      "INFO:tensorflow:loss = 0.005280449, step = 201 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.708\n",
      "INFO:tensorflow:loss = 0.00556931, step = 301 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.652\n",
      "INFO:tensorflow:loss = 0.006012776, step = 401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.288\n",
      "INFO:tensorflow:loss = 0.003854424, step = 501 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.797\n",
      "INFO:tensorflow:loss = 0.008143416, step = 601 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.746\n",
      "INFO:tensorflow:loss = 0.005581686, step = 701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.931\n",
      "INFO:tensorflow:loss = 0.005760736, step = 801 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.522\n",
      "INFO:tensorflow:loss = 0.004544206, step = 901 (0.261 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0046248864.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-14:10:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-14:10:48\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0056809327, rmse = 0.075329676\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./model_trained/export/exporter/temp-1531231848/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def make_input_fn(indf, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    indf,\n",
    "    indf['num_trips'],\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True)\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      'day_of_week': tf.placeholder(tf.int32, [None]),\n",
    "      'start_station_id': tf.placeholder(tf.int32, [None]),\n",
    "      'rainy': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "  # linear model\n",
    "  station_col = tf.feature_column.categorical_column_with_hash_bucket('start_station_id', 5000, tf.int32)\n",
    "  station_embed = tf.feature_column.embedding_column(station_col, 2)  # embed dimension\n",
    "  embed_layer = tf.feature_column.input_layer(features, station_embed)\n",
    "  \n",
    "  cat_cols = [\n",
    "    tf.feature_column.categorical_column_with_identity('day_of_week', num_buckets = 8),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('rainy', ['false', 'true'])\n",
    "  ]\n",
    "  cat_cols = [tf.feature_column.indicator_column(col) for col in cat_cols]\n",
    "  other_inputs = tf.feature_column.input_layer(features, cat_cols)\n",
    "  \n",
    "  all_inputs = tf.concat([embed_layer, other_inputs], axis=1)\n",
    "  predictions = tf.layers.dense(all_inputs, 1)  # linear model\n",
    "  \n",
    "  # 2. Loss function, training/eval ops\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        labels = tf.expand_dims(labels, -1)\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step(),\n",
    "            learning_rate = 0.01,\n",
    "            optimizer = \"Ftrl\")\n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        }\n",
    "  else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "  \n",
    "  # 3. Create predictions\n",
    "  predictions_dict = {\n",
    "    \"predicted\": predictions,\n",
    "    \"station_embed\": embed_layer\n",
    "  }\n",
    "    \n",
    "  # 4. Create export outputs\n",
    "  export_outputs = {\n",
    "    \"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)\n",
    "  }\n",
    "\n",
    "  # 5. Return EstimatorSpec\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs)\n",
    "\n",
    "def train_and_evaluate(output_dir, nsteps):\n",
    "  estimator = tf.estimator.Estimator(\n",
    "                       model_fn = model_fn,\n",
    "                       model_dir = output_dir)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = make_input_fn(train_df, None),\n",
    "                       max_steps = nsteps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = make_input_fn(eval_df, 1),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "  \n",
    "import shutil\n",
    "OUTDIR='./model_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True)\n",
    "train_and_evaluate(OUTDIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED              STATION_EMBED\n",
      "[0.08361567556858063]  [3.662878270915826e-06, -0.0011744950897991657]\n",
      "[0.0871109813451767]   [3.662878270915826e-06, -0.0011744950897991657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-07-10 14:11:28.645852: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "EXPORTDIR=./model_trained/export/exporter/\n",
    "MODELDIR=$(ls $EXPORTDIR | tail -1)\n",
    "gcloud ml-engine local predict --model-dir=${EXPORTDIR}/${MODELDIR} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore embeddings\n",
    "\n",
    "Let's explore the embeddings for some stations. Let's look at stations with overall similar numbers of trips. Do they have similar embedding values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations=\"\"\"\n",
    "  SELECT\n",
    "    COUNT(starttime) as num_trips,\n",
    "    MAX(start_station_name) AS station_name,\n",
    "    start_station_id\n",
    "  FROM `bigquery-public-data.new_york.citibike_trips`\n",
    "  GROUP BY start_station_id\n",
    "  ORDER BY num_trips desc\n",
    "\"\"\"\n",
    "stationsdf = bq.Query(stations).execute().result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>359182</td>\n",
       "      <td>Pershing Square North</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291615</td>\n",
       "      <td>E 17 St &amp; Broadway</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277060</td>\n",
       "      <td>Lafayette St &amp; E 8 St</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275348</td>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268807</td>\n",
       "      <td>8 Ave &amp; W 31 St N</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_trips           station_name  start_station_id\n",
       "0     359182  Pershing Square North               519\n",
       "1     291615     E 17 St & Broadway               497\n",
       "2     277060  Lafayette St & E 8 St               293\n",
       "3     275348        W 21 St & 6 Ave               435\n",
       "4     268807      8 Ave & W 31 St N               521"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2828</td>\n",
       "      <td>W 87 St &amp; West End Ave</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2808</td>\n",
       "      <td>47 Ave &amp; 31 St</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2785</td>\n",
       "      <td>21 St &amp; 41 Ave</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2734</td>\n",
       "      <td>Hanson Pl &amp; Ashland Pl</td>\n",
       "      <td>3429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2678</td>\n",
       "      <td>E 67 St &amp; Park Ave</td>\n",
       "      <td>3133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_trips            station_name  start_station_id\n",
       "500       2828  W 87 St & West End Ave              3287\n",
       "501       2808          47 Ave & 31 St              3221\n",
       "502       2785          21 St & 41 Ave              3237\n",
       "503       2734  Hanson Pl & Ashland Pl              3429\n",
       "504       2678      E 67 St & Park Ave              3133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationsdf[500:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.json\n"
     ]
    }
   ],
   "source": [
    "%writefile test.json\n",
    "{\"day_of_week\": 4, \"start_station_id\": 435, \"rainy\": \"true\"}\n",
    "{\"day_of_week\": 4, \"start_station_id\": 521, \"rainy\": \"true\"}\n",
    "{\"day_of_week\": 4, \"start_station_id\": 3221, \"rainy\": \"true\"}\n",
    "{\"day_of_week\": 4, \"start_station_id\": 3237, \"rainy\": \"true\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "435 and 521 are in the first list (of top rental locations) and in the Chelsea Market area.\n",
    "3221 and 3237 are in the second list (of rare rentals) and in Long Island.\n",
    "Do the embeddings reflect this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED              STATION_EMBED\n",
      "[0.08976395428180695]  [-2.3062024411046878e-05, 0.008066227659583092]\n",
      "[0.08778293430805206]  [-3.2270579595206073e-06, 0.0011660171439871192]\n",
      "[0.08674221485853195]  [1.1034319868485909e-05, -0.00245896028354764]\n",
      "[0.08657103031873703]  [9.333280104328878e-06, -0.0030552244279533625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-07-10 14:11:42.625068: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "EXPORTDIR=./model_trained/export/exporter/\n",
    "MODELDIR=$(ls $EXPORTDIR | tail -1)\n",
    "gcloud ml-engine local predict --model-dir=${EXPORTDIR}/${MODELDIR} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the first dimension of the embedding is almost zero in all cases. So, we only need a one dimensional embedding. And in that, it is quite clear that the Manhattan, frequent rental stations have positive values (0.0081, 0.0011) whereas the Long Island, rare rental stations have negative values (-0.0025, -0.0031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
