{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification from scratch with TPUs on Cloud ML Engine using ResNet\n",
    "\n",
    "This notebook demonstrates how to do image classification from scratch on a flowers dataset using TPUs and the resnet trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'cloud-training-demos' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'cloud-training-demos-ml' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert JPEG images to TensorFlow Records\n",
    "\n",
    "My dataset consists of JPEG images in Google Cloud Storage. I have two CSV files that are formatted as follows:\n",
    "   image-name, category\n",
    "\n",
    "Instead of reading the images from JPEG each time, we'll convert the JPEG data and store it as TF Records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-data/img/flower_photos/daisy/754296579_30a9ae018c_n.jpg,daisy\n",
      "gs://cloud-ml-data/img/flower_photos/dandelion/18089878729_907ed2c7cd_m.jpg,dandelion\n",
      "gs://cloud-ml-data/img/flower_photos/dandelion/284497199_93a01f48f6.jpg,dandelion\n",
      "gs://cloud-ml-data/img/flower_photos/dandelion/3554992110_81d8c9b0bd_m.jpg,dandelion\n",
      "gs://cloud-ml-data/img/flower_photos/daisy/4065883015_4bb6010cb7_n.jpg,daisy\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil cat gs://cloud-ml-data/img/flower_photos/train_set.csv | head -5 > /tmp/input.csv\n",
    "cat /tmp/input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n",
      "dandelion\n",
      "roses\n",
      "sunflowers\n",
      "tulips\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil cat gs://cloud-ml-data/img/flower_photos/train_set.csv  | sed 's/,/ /g' | awk '{print $2}' | sort | uniq > /tmp/labels.txt\n",
    "cat /tmp/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Enable TPU service account\n",
    "\n",
    "Allow Cloud ML Engine to access the TPU and bill to your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "SVC_ACCOUNT=$(curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\"  \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT}:getConfig \\\n",
    "              | grep tpuServiceAccount | tr '\"' ' ' | awk '{print $3}' )\n",
    "echo \"Enabling TPU service account $SVC_ACCOUNT to act as Cloud ML Service Agent\"\n",
    "gcloud projects add-iam-policy-binding $PROJECT \\\n",
    "    --member serviceAccount:$SVC_ACCOUNT --role roles/ml.serviceAgent\n",
    "echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clone the TPU repo\n",
    "\n",
    "Let's git clone the repo and get the preprocessing and model files. The model code has imports of the form:\n",
    "<pre>\n",
    "import resnet_model as model_lib\n",
    "</pre>\n",
    "We will need to change this to:\n",
    "<pre>\n",
    "from . import resnet_model as model_lib\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting copy_resnet_files.sh\n"
     ]
    }
   ],
   "source": [
    "%writefile copy_resnet_files.sh\n",
    "#!/bin/bash\n",
    "rm -rf tpu\n",
    "git clone https://github.com/tensorflow/tpu\n",
    "cd tpu\n",
    "TFVERSION=$1\n",
    "echo \"Switching to version r$TFVERSION\"\n",
    "git checkout r$TFVERSION\n",
    "cd ..\n",
    "  \n",
    "MODELCODE=tpu/models/official/resnet\n",
    "OUTDIR=mymodel\n",
    "rm -rf $OUTDIR\n",
    "\n",
    "# preprocessing\n",
    "cp -r imgclass $OUTDIR   # brings in setup.py and __init__.py\n",
    "cp tpu/tools/datasets/jpeg_to_tf_record.py $OUTDIR/trainer/preprocess.py\n",
    "\n",
    "# model: fix imports\n",
    "for FILE in $(ls -p $MODELCODE | grep -v /); do\n",
    "    CMD=\"cat $MODELCODE/$FILE \"\n",
    "    for f2 in $(ls -p $MODELCODE | grep -v /); do\n",
    "        MODULE=`echo $f2 | sed 's/.py//g'`\n",
    "        CMD=\"$CMD | sed 's/^import ${MODULE}/from . import ${MODULE}/g' \"\n",
    "    done\n",
    "    CMD=\"$CMD > $OUTDIR/trainer/$FILE\"\n",
    "    eval $CMD\n",
    "done\n",
    "find $OUTDIR\n",
    "echo \"Finished copying files into $OUTDIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!bash ./copy_resnet_files.sh $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try preprocessing locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 5 labels, from daisy to tulips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/scipy/optimize/_minimize.py:32: ImportWarning: Not importing directory '/usr/local/envs/py2env/lib/python2.7/site-packages/scipy/optimize/lbfgsb': missing __init__.py\n",
      "  from .lbfgsb import _minimize_lbfgsb\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: ImportWarning: Not importing directory '/usr/local/envs/py2env/lib/python2.7/site-packages/scipy/spatial/qhull': missing __init__.py\n",
      "  from .qhull import *\n",
      "2018-06-26 00:20:44.080585: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mymodel\n",
    "  \n",
    "rm -rf /tmp/out\n",
    "python -m trainer.preprocess \\\n",
    "       --train_csv /tmp/input.csv \\\n",
    "       --validation_csv /tmp/input.csv \\\n",
    "       --labels_file /tmp/labels.txt \\\n",
    "       --project_id $PROJECT \\\n",
    "       --output_dir /tmp/out --runner=DirectRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 384\r\n",
      "-rw-r--r-- 1 root root 195698 Jun 26 00:20 train-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root 195698 Jun 26 00:20 validation-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /tmp/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�l\u0000\u0000\u0000\u0000\u0000\u0000�+��\r\n",
      "��\u0001\r\n",
      "��\u0001\r\n",
      "\r",
      "image/encoded\u0012��\u0001\r\n",
      "��\u0001\r\n",
      "��\u0001����\u0000\u0010JFIF\u0000\u0001\u0001\u0000\u0000\u0001\u0000\u0001\u0000\u0000��\u0004HICC_PROFILE\u0000\u0001\u0001\u0000\u0000\u00048appl\u0002 \u0000\u0000mntrRGB XYZ \u0007�\u0000\b\u0000\r",
      "\u0000\u0010\u0000\u0006\u0000\u0007acspAPPL\u0000\u0000\u0000\u0000appl\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000��\u0000\u0001\u0000\u0000\u0000\u0000�-appl\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\f",
      "cprt\u0000\u0000\u0002\u0004\u0000\u0000\u0000Hdesc\u0000\u0000\u0001\u0014\u0000\u0000\u00001wtpt\u0000\u0000\u0001H\u0000\u0000\u0000\u0014rTRC\u0000\u0000\u0001\\\u0000\u0000\u0000\u000egTRC\u0000\u0000\u0001\\\u0000\u0000\u0000\u000ebTRC\u0000\u0000\u0001\\\u0000\u0000\u0000\u000erXYZ\u0000\u0000\u0001l\u0000\u0000\u0000\u0014gXYZ\u0000\u0000\u0001�\u0000\u0000\u0000\u0014bXYZ\u0000\u0000\u0001�\u0000\u0000\u0000\u0014vcgt\u0000\u0000\u0001�\u0000\u0000\u00000chad\u0000\u0000\u0001�\u0000\u0000\u0000,dscm\u0000\u0000\u0002L\u0000\u0000\u0001�desc\u0000\u0000\u0000\u0000\u0000\u0000\u0000\r",
      "sRGB Profile\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\r",
      "sRGB Profile\u0000\u0000\u0000\u0000XYZ \u0000\u0000\u0000\u0000\u0000\u0000�Q\u0000\u0001\u0000\u0000\u0000\u0001\u0016�curv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u00023\u0000\u0000XYZ \u0000\u0000\u0000\u0000\u0000\u0000o�\u0000\u00008�\u0000\u0000\u0003�XYZ \u0000\u0000\u0000\u0000\u0000\u0000b�\u0000\u0000��\u0000\u0000\u0018�XYZ \u0000\u0000\u0000\u0000\u0000\u0000$�\u0000\u0000\u000f�\u0000\u0000��vcgt\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000�H\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000�H\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000�H\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000sf32\u0000\u0000\u0000\u0000\u0000\u0001\f",
      "B\u0000\u0000\u0005����&\u0000\u0000\u0007�\u0000\u0000����������\u0000\u0000\u0003�\u0000\u0000�ntext\u0000\u0000\u0000\u0000Copyright 1998 - 2003 Apple Computer Inc., all rights reserved.\u0000mluc\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000f\u0000\u0000\u0000\f",
      "enUS\u0000\u0000\u0000\u0018\u0000\u0000\u0001�esES\u0000\u0000\u0000\u0016\u0000\u0000\u00012daDK\u0000\u0000\u0000 \u0000\u0000\u0001pdeDE\u0000\u0000\u0000\u0016\u0000\u0000\u0001HfiFI\u0000\u0000\u0000\u001a\u0000\u0000\u0000�frFU\u0000\u0000\u0000\u0016\u0000\u0000\u0000�itIT\u0000\u0000\u0000\u0018\u0000\u0000\u0001�nlNL\u0000\u0000\u0000\u0018\u0000\u0000\u0001�noNO\u0000\u0000\u0000\u0016\u0000\u0000\u0000�ptBR\u0000\u0000\u0000\u0016\u0000\u0000\u00012svSE\u0000\u0000\u0000\u0016\u0000\u0000\u0000�jaJP\u0000\u0000\u0000\u0016\u0000\u0000\u0001\r\n",
      "koKR\u0000\u0000\u0000\u0012\u0000\u0000\u0001�zhTW\u0000\u0000\u0000\u0012\u0000\u0000\u0001 zhCN\u0000\u0000\u0000\u0012\u0000\u0000\u0001^\u0000s\u0000R\u0000G\u0000B\u0000-\u0000p\u0000r\u0000o\u0000f\u0000i\u0000i\u0000l\u0000i\u0000s\u0000R\u0000G\u0000B\u0000-\u0000p\u0000r\u0000o\u0000f\u0000i\u0000l\u0000P\u0000r\u0000o\u0000f\u0000i\u0000l\u0000 \u0000s\u0000R\u0000V\u0000B\u0000s\u0000R\u0000G\u0000B\u0000 0�0�0�0�0�0�\u0000s\u0000R\u0000G\u0000B\u0000 �r_icϏ�\u0000P\u0000e\u0000r\u0000f\u0000i\u0000l\u0000 \u0000s\u0000R\u0000G\u0000B\u0000s\u0000R\u0000G\u0000B\u0000-\u0000P\u0000r\u0000o\u0000f\u0000i\u0000l\u0000s\u0000R\u0000G\u0000B\u0000 cϏ�e�N�\u0000s\u0000R\u0000G\u0000B\u0000-\u0000b\u0000e\u0000s\u0000k\u0000r\u0000i\u0000v\u0000e\u0000l\u0000s\u0000e\u0000s\u0000R\u0000G\u0000B\u0000-\u0000p\u0000r\u0000o\u0000f\u0000i\u0000e\u0000l\u0000s\u0000R\u0000G\u0000B\u0000 �\u0004�\\�\f",
      "�|\u0000P\u0000r\u0000o\u0000f\u0000i\u0000l\u0000o\u0000 \u0000s\u0000R\u0000G\u0000B\u0000s\u0000R\u0000G\u0000B\u0000 \u0000P\u0000r\u0000o\u0000f\u0000i\u0000l\u0000e\u0000\u0000��\u0000C\u0000\u0003\u0002\u0002\u0003\u0002\u0002\u0003\u0003\u0003\u0003\u0004\u0003\u0003\u0004\u0005\b\u0005\u0005\u0004\u0004\u0005\r\n",
      "\u0007\u0007\u0006\b\f",
      "\r\n",
      "\f",
      "\f",
      "\u000b",
      "\r\n",
      "\u000b",
      "\u000b",
      "\r",
      "\u000e\u0012\u0010\r",
      "\u000e\u0011\u000e\u000b",
      "\u000b",
      "\u0010\u0016\u0010\u0011\u0013\u0014\u0015\u0015\u0015\f",
      "\u000f\u0017\u0018\u0016\u0014\u0018\u0012\u0014\u0015\u0014��\u0000C\u0001\u0003\u0004\u0004\u0005\u0004\u0005\t\u0005\u0005\t\u0014\r",
      "\u000b",
      "\r",
      "\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014\u0014��\u0000\u0011\b\u0000�\u0001@\u0003\u0001\u0011\u0000\u0002\u0011\u0001\u0003\u0011\u0001��\u0000\u001d",
      "\u0000\u0000\u0001\u0004\u0003\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0006\u0004\u0005\u0007\b\u0000\u0002\u0003\u0001\t��\u0000I\u0010\u0000\u0001\u0003\u0003\u0003\u0002\u0004\u0003\u0005\u0006\u0003\u0005\u0007\u0002\u0007\u0000\u0001\u0002\u0003\u0004\u0000\u0005\u0011\u0006\u0012!\u00071\u0013AQa\b\"q\u0014\u0015���\t#2BR�r��\u0016$3b�\u0017%S����Cs56DT�����\u0000\u001c",
      "\u0001\u0000\u0001\u0005\u0001\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0003\u0000\u0001\u0002\u0004\u0005\u0006\u0007\b��\u0000;\u0011\u0000\u0002\u0001\u0003\u0003\u0003\u0002\u0003\u0006\u0006\u0001\u0003\u0004\u0003\u0000\u0000\u0000\u0001\u0002\u0003\u0011!\u0004\u00121\u0005AQ\u0013a\"q�\u00062����\u0014#B����\u0007$R\u0015\u00164rb����\u0000\f",
      "\u0003\u0001\u0000\u0002\u0011\u0003\u0011\u0000?\u0000�e�\u0010\u0013\u000eO�8�)\u000eg~)\b�\u001d",
      "�\b���\u0011�?\u001aa�m�\u0014�����{�a� S�y�ӊB3\u001c",
      "R\u0015�\t4�sͤ�<�\u0015���!�{�\u0002��3\u0014�m�C\u00188�\u0011��\u0011�+EŊ\u0014ݑ\tg\u0003�h�JA�5�9�v;��)�+\u000e�3�{$�E^�\u001b\f",
      "�ƥ\u0012O�[A�\u000f)�\u000f\u001ay���T�.�b�dK\u0016#�(q�\\uv��dv���\u0013�S���\u0016\u0006I\u0002�k�{ϟ!W\\�U�D�H\u0016����5v��#!]�����>�\u001a���⃍'o�Uզ�{�J\u000fuD��g���e�\u0004\u0002p+�����H�mZUL�\u0000G�_%c[��\r\n"
     ]
    }
   ],
   "source": [
    "!head /tmp/out/train-00000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now run it over full training and evaluation datasets.  This will happen in Cloud Dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mymodel\n",
    "gsutil -m rm -rf gs://${BUCKET}/tpu/resnet/data\n",
    "python -m trainer.preprocess \\\n",
    "       --train_csv gs://cloud-ml-data/img/flower_photos/train_set.csv \\\n",
    "       --validation_csv gs://cloud-ml-data/img/flower_photos/eval_set.csv \\\n",
    "       --labels_file /tmp/labels.txt \\\n",
    "       --project_id $PROJECT \\\n",
    "       --output_dir gs://${BUCKET}/tpu/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The above preprocessing step will take <b>15-20 minutes</b>. Wait for the job to finish before you proceed. Navigate to [Cloud Dataflow section of GCP web console](https://console.cloud.google.com/dataflow) to monitor job progress. You will see something like this <img src=\"dataflow.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Alternately, you can simply copy my already preprocessed files and proceed to the next step:\n",
    "<pre>\n",
    "gsutil -m cp gs://cloud-training-demos/tpu/resnet/data/* gs://${BUCKET}/tpu/resnet/copied_data\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00000-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00001-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00002-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00003-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00004-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00005-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00006-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00007-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00008-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00009-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00010-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00011-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/train-00012-of-00013\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/validation-00000-of-00003\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/validation-00001-of-00003\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/validation-00002-of-00003\n",
      "gs://cloud-training-demos-ml/tpu/resnet/data/tmp/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/tpu/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train on the Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--num_train_images=3300  --num_eval_images=370  --num_label_classes=5\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo -n \"--num_train_images=$(gsutil cat gs://cloud-ml-data/img/flower_photos/train_set.csv | wc -l)  \"\n",
    "echo -n \"--num_eval_images=$(gsutil cat gs://cloud-ml-data/img/flower_photos/eval_set.csv | wc -l)  \"\n",
    "echo \"--num_label_classes=$(cat /tmp/labels.txt | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "TOPDIR=gs://${BUCKET}/tpu/resnet\n",
    "OUTDIR=${TOPDIR}/trained\n",
    "JOBNAME=imgclass_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR  # Comment out this line to continue training from the last time\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.resnet_main \\\n",
    "  --package-path=$(pwd)/mymodel/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=BASIC_TPU \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --data_dir=${TOPDIR}/data \\\n",
    "  --model_dir=${OUTDIR} \\\n",
    "  --resnet_depth=18 \\\n",
    "  --train_batch_size=128 --eval_batch_size=32 --skip_host_call=True \\\n",
    "  --train_steps=1000 \\\n",
    "  --num_train_images=3300  --num_eval_images=370  --num_label_classes=5 \\\n",
    "  --export_dir=${OUTDIR}/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The above training job will take 15-20 minutes. \n",
    "Wait for the job to finish before you proceed. \n",
    "Navigate to [Cloud ML Engine section of GCP web console](https://console.cloud.google.com/mlengine) \n",
    "to monitor job progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/tpu/resnet/trained/export/\n",
      "gs://cloud-training-demos-ml/tpu/resnet/trained/export/1529987998/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying flowers resnet from gs://cloud-training-demos-ml/tpu/resnet/trained/export/1529987998/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......\n",
      "..................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"flowers\"\n",
    "MODEL_VERSION=resnet\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete --quiet ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use saved_model_cli to find out what inputs the model expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['image_bytes'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: Placeholder:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['classes'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: ArgMax:0\n",
      "  outputs['probabilities'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 5)\n",
      "      name: softmax_tensor:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "saved_model_cli show --dir $(gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/ | tail -1) --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model expects image_bytes.  This is typically base64 encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To predict with the model, let's take one of the example images that is available on Google Cloud Storage <img src=\"http://storage.googleapis.com/cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\" /> and convert it to a base64-encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64, sys, json\n",
    "import tensorflow as tf\n",
    "with tf.gfile.FastGFile('gs://cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg', 'r') as ifp:\n",
    "  with open('test.json', 'w') as ofp:\n",
    "    image_data = ifp.read()\n",
    "    img = base64.b64encode(image_data)\n",
    "    json.dump({\"image_bytes\": {\"b64\": img}}, ofp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 56992 Jun 26 05:33 test.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSES  PROBABILITIES\n",
      "3        [0.0012481402372941375, 0.0010495249880477786, 7.82029837864684e-06, 0.9976732134819031, 2.1333773474907503e-05]\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=flowers --version=resnet --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does CLASS no. 3 correspond to? (remember that classes is 0-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflowers\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "head -4 /tmp/labels.txt | tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<pre>\n",
    "# Copyright 2018 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
