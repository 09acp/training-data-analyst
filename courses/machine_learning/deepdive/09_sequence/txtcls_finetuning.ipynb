{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Text Classification using TensorFlow/Keras on Cloud ML Engine </h1>\n",
    "<h3>Leveraging a pre-trained embedding</h3>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Downloading a pre-trained text embedding\n",
    "<li> Creating a text classification model using Keras and the Estimator API \n",
    "<li> Training on Cloud ML Engine\n",
    "<li> Deploying model\n",
    "<li> Predicting with model\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'vijays-sandbox-ml'\n",
    "PROJECT = 'vijays-sandbox'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-requisites\n",
    "Ensure you have the training files generated from the txtcls_fromscratch notebook. If you don't, go back and run the <a href=\"txtcls_fromscratch.ipynb\">txtcls_fromscratch</a> notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!wc -l data/txtcls/*.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Download Pre-trained Embedding\n",
    "\n",
    "In previous notebook we trained our word embedding from scratch. Often times we get better performance from leveraging a pre-trained embedding. This is a similar concept to transfer learning during image classification.\n",
    "\n",
    "We will use the popular GloVe embedding which is trained on Wikipedia as well as various news sources like the NYTimes.\n",
    "\n",
    "You can read more about Glove at the project homepage: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "*Note: The download is about 900MB so the following cell may take some time to run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "unzip glove.6B.zip -d data/txtcls/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow/Keras Code\n",
    "\n",
    "Please explore the code in this <a href=\"txtclsmodel/trainer\">directory</a>: `model.py` contains the TensorFlow model and `task.py` parses command line arguments and launches off the training job. \n",
    "\n",
    "This is the same code as in the previous notebook. The only difference is we invoke it with the `--embedding_path` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run Locally\n",
    "Let's make sure the code compiles and works locally by running for a fraction of an epoch. Note the new `--embedding_path` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "rm -rf trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/txtclsmodel/trainer \\\n",
    "   -- \\\n",
    "   --output_dir=trained \\\n",
    "   --train_data_path=${PWD}/data/txtcls/train.tsv \\\n",
    "   --eval_data_path=${PWD}/data/txtcls/eval.tsv \\\n",
    "   --embedding_path=${PWD}/data/txtcls/glove.6B.200d.txt \\\n",
    "   --num_epochs=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on the Cloud\n",
    "\n",
    "Let's first copy our embedding file to the cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp data/txtcls/glove.6B.200d.txt gs://$BUCKET/txtcls/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/txtcls/trained_finetune\n",
    "JOBNAME=txtcls_$(date -u +%y%m%d_%H%M%S)\n",
    "REGION=us-central1\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    " --region=$REGION \\\n",
    " --module-name=trainer.task \\\n",
    " --package-path=${PWD}/txtclsmodel/trainer \\\n",
    " --job-dir=$OUTDIR \\\n",
    " --scale-tier=BASIC_GPU \\\n",
    " --runtime-version=$TFVERSION \\\n",
    " -- \\\n",
    " --output_dir=$OUTDIR \\\n",
    " --train_data_path=gs://${BUCKET}/txtcls/train.csv \\\n",
    " --eval_data_path=gs://${BUCKET}/txtcls/eval.csv \\\n",
    " --embedding_path=gs://${BUCKET}/txtcls/glove.6B.200d.txt \\\n",
    " --num_epochs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Monitor training with TensorBoard\n",
    "If tensorboard appears blank try refreshing after 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/txtcls/trained_finetune'.format(BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results\n",
    "What accuracy did you get? Was it an improvement over training the embedding from scratch? \n",
    "\n",
    "While the final accuracy may not change significantly, you should notice the model was able to converge to it much more quickly given the pre-trained embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Deploy trained model \n",
    "\n",
    "Once your training completes you will see your exported models in the output directory specified in Google Cloud Storage. \n",
    "\n",
    "You should see one model for each training checkpoint (default is every 1000 steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/txtcls/trained_finetune/export/exporter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"txtcls\"\n",
    "MODEL_VERSION=\"v1_finetune\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/txtcls/trained_finetune/export/exporter/ | tail -1)\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME} --quiet\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get Predictions\n",
    "\n",
    "Here are some actual hacker news headlines gathered from July 2018. These titles were not part of the training or evaluation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "techcrunch=[\n",
    "  'Uber shuts down self-driving trucks unit',\n",
    "  'Grover raises €37M Series A to offer latest tech products as a subscription',\n",
    "  'Tech companies can now bid on the Pentagon’s $10B cloud contract'\n",
    "]\n",
    "nytimes=[\n",
    "  '‘Lopping,’ ‘Tips’ and the ‘Z-List’: Bias Lawsuit Explores Harvard’s Admissions',\n",
    "  'A $3B Plan to Turn Hoover Dam into a Giant Battery',\n",
    "  'A MeToo Reckoning in China’s Workplace Amid Wave of Accusations'\n",
    "]\n",
    "github=[\n",
    "  'Show HN: Moon – 3kb JavaScript UI compiler',\n",
    "  'Show HN: Hello, a CLI tool for managing social media',\n",
    "  'Firefox Nightly added support for time-travel debugging'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our serving input function expects the already tokenized representations of the headlines, so we do that pre-processing in the code before calling the REST API.\n",
    "\n",
    "Note: Ideally we would do these transformation in the tensorflow graph directly instead of relying on separate client pre-processing code (see: [training-serving skew](https://developers.google.com/machine-learning/guides/rules-of-ml/#training_serving_skew)), howevever the keras pre-processing functions we're using are not native tensorflow functions so this is not possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uber shuts down self-driving trucks unit\n",
      " github    : 1.11331166863e-06\n",
      " nytimes   : 0.999956488609\n",
      " techcrunch: 4.24026038672e-05\n",
      "\n",
      "Grover raises €37M Series A to offer latest tech products as a subscription\n",
      " github    : 3.69702429452e-05\n",
      " nytimes   : 0.97977989912\n",
      " techcrunch: 0.0201830491424\n",
      "\n",
      "Tech companies can now bid on the Pentagon’s $10B cloud contract\n",
      " github    : 0.000980124576017\n",
      " nytimes   : 0.891622960567\n",
      " techcrunch: 0.107396923006\n",
      "\n",
      "‘Lopping,’ ‘Tips’ and the ‘Z-List’: Bias Lawsuit Explores Harvard’s Admissions\n",
      " github    : 3.89208285013e-14\n",
      " nytimes   : 1.0\n",
      " techcrunch: 8.62220503328e-11\n",
      "\n",
      "A $3B Plan to Turn Hoover Dam into a Giant Battery\n",
      " github    : 0.0126319322735\n",
      " nytimes   : 0.978058815002\n",
      " techcrunch: 0.00930932350457\n",
      "\n",
      "A MeToo Reckoning in China’s Workplace Amid Wave of Accusations\n",
      " github    : 2.3520786962e-14\n",
      " nytimes   : 1.0\n",
      " techcrunch: 4.22925854494e-14\n",
      "\n",
      "Show HN: Moon – 3kb JavaScript UI compiler\n",
      " github    : 1.0\n",
      " nytimes   : 1.3027193087e-15\n",
      " techcrunch: 8.53409834798e-15\n",
      "\n",
      "Show HN: Hello, a CLI tool for managing social media\n",
      " github    : 1.0\n",
      " nytimes   : 1.02355810747e-15\n",
      " techcrunch: 3.02873994466e-15\n",
      "\n",
      "Firefox Nightly added support for time-travel debugging\n",
      " github    : 0.946214497089\n",
      " nytimes   : 0.0513937398791\n",
      " techcrunch: 0.00239177607\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "requests = techcrunch+nytimes+github\n",
    "\n",
    "# Tokenize and pad sentences using same mapping used in the deployed model\n",
    "tokenizer = pickle.load( open( \"txtclsmodel/tokenizer.pickled\", \"rb\" ) )\n",
    "\n",
    "requests_tokenized = tokenizer.texts_to_sequences(requests)\n",
    "requests_tokenized = sequence.pad_sequences(requests_tokenized,maxlen=50)\n",
    "\n",
    "# JSON format the requests\n",
    "request_data = {'instances':requests_tokenized.tolist()}\n",
    "\n",
    "# Authenticate and call CMLE prediction API \n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'txtcls', 'v1_finetune')\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "\n",
    "# Format and print response\n",
    "for i in xrange(len(requests)):\n",
    "  print('\\n{}'.format(requests[i]))\n",
    "  print(' github    : {}'.format(response['predictions'][i]['dense_1'][0]))\n",
    "  print(' nytimes   : {}'.format(response['predictions'][i]['dense_1'][1]))\n",
    "  print(' techcrunch: {}'.format(response['predictions'][i]['dense_1'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bonus: Native Tensorflow Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Why Native?\n",
    "\n",
    "Up until now we've been using pure python functions to do our data pre-processing. This is fine during training, but during serving it adds the limitation that we need a python client in the prediction pipeline.\n",
    "\n",
    "This limits your serving flexibility. For example, lets say you want to be able to serve this model locally (offline) on a mobile phone. How would you do it? It's non trivial to execute python code on Android.\n",
    "\n",
    "A better way would be to have all of our serving pre-processing to be done using native Tensorflow operations. As long as we stick to native operations, we can take advantage of Tensorflow's hardware agnostic execution engine, and leverage the huge Engineering efforts the Tensorflow team put into making sure our code works whether we're running on a server, mobile, or an embedded device!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow/Keras Code (Native)\n",
    "\n",
    "Please explore the code in this <a href=\"txtclsmodel/trainer\">directory</a>: `model_native.py` contains the TensorFlow model and `task.py` parses command line arguments and launches off the training job. \n",
    "\n",
    "In particular look for the follwing:\n",
    "\n",
    "1. [tf.keras.preprocessing.text.Tokenizer.fit_on_texts()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#fit_on_texts) to generate a mapping from our word vocabulary to integers\n",
    "2. [tf.gfile](https://www.tensorflow.org/api_docs/python/tf/gfile/GFile) to write the vocabulary mapping to disk\n",
    "3. [tf.contrib.lookup.index_table_from_file()](https://www.tensorflow.org/api_docs/python/tf/contrib/lookup/index_table_from_file) to encode our sentences into a tensor of their respective word-integers, based on the vocabulary mapping written to disk in the previous step\n",
    "4. [tf.pad](https://www.tensorflow.org/api_docs/python/tf/pad) and [tf.slice](https://www.tensorflow.org/api_docs/python/tf/slice) to pad all sequences to be the same length\n",
    "\n",
    "Note that we will leave our training/evaluation input_fn as is. However we will modify our serving_input_fn to use **3.** and **4.** which are both native Tensorflow functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run Locally (Native)\n",
    "Let's make sure the code compiles and works locally by running for a fraction of an epoch. Note the new `--native` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/content/datalab/training-data-analyst/courses/machine_learning/deepdive/09_sequence/txtclsmodel/trainer/task.py\", line 62, in <module>\n",
      "    model_native.train_and_evaluate(output_dir, hparams)\n",
      "  File \"trainer/model_native.py\", line 319, in train_and_evaluate\n",
      "    f.write(\"{},{}\\n\".format(word, index))\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 103, in write\n",
      "    self._prewrite_check()\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 89, in _prewrite_check\n",
      "    compat.as_bytes(self.__name), compat.as_bytes(self.__mode), status)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: trained/vocab.txt; No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=${PWD}/txtcls_trained\n",
    "rm -rf $OUTDIR\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/txtclsmodel/trainer \\\n",
    "   -- \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_data_path=${PWD}/data/txtcls/train.tsv \\\n",
    "   --eval_data_path=${PWD}/data/txtcls/eval.tsv \\\n",
    "   --embedding_path=${PWD}/data/txtcls/glove.6B.200d.txt \\\n",
    "   --native \\\n",
    "   --num_epochs=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on the Cloud (Native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/txtcls/trained_finetune_native\n",
    "JOBNAME=txtcls_$(date -u +%y%m%d_%H%M%S)\n",
    "REGION=us-central1\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    " --region=$REGION \\\n",
    " --module-name=trainer.task \\\n",
    " --package-path=${PWD}/txtclsmodel/trainer \\\n",
    " --job-dir=$OUTDIR \\\n",
    " --scale-tier=BASIC_GPU \\\n",
    " --runtime-version=$TFVERSION \\\n",
    " -- \\\n",
    " --output_dir=$OUTDIR \\\n",
    " --train_data_path=gs://${BUCKET}/txtcls/train.csv \\\n",
    " --eval_data_path=gs://${BUCKET}/txtcls/eval.csv \\\n",
    " --embedding_path=gs://${BUCKET}/txtcls/glove.6B.200d.txt \\\n",
    " --native \\\n",
    " --num_epochs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Deploy trained model (Native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......\n",
      "...............................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"txtcls\"\n",
    "MODEL_VERSION=\"v1_finetune_native\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/txtcls/trained_finetune_native/export/exporter/ | tail -1)\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME} --quiet\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get Predictions (Native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "techcrunch=[\n",
    "  'Uber shuts down self-driving trucks unit',\n",
    "  'Grover raises €37M Series A to offer latest tech products as a subscription',\n",
    "  'Tech companies can now bid on the Pentagon’s $10B cloud contract'\n",
    "]\n",
    "nytimes=[\n",
    "  '‘Lopping,’ ‘Tips’ and the ‘Z-List’: Bias Lawsuit Explores Harvard’s Admissions',\n",
    "  'A $3B Plan to Turn Hoover Dam into a Giant Battery',\n",
    "  'A MeToo Reckoning in China’s Workplace Amid Wave of Accusations'\n",
    "]\n",
    "github=[\n",
    "  'Show HN: Moon – 3kb JavaScript UI compiler',\n",
    "  'Show HN: Hello, a CLI tool for managing social media',\n",
    "  'Firefox Nightly added support for time-travel debugging'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note how we can now feed the titles directly to the model! All the pre-processing is done for us inside of the Tensorflow serving_input_fn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uber shuts down self-driving trucks unit\n",
      " github    : 0.0131800081581\n",
      " nytimes   : 0.442704319954\n",
      " techcrunch: 0.544115662575\n",
      "\n",
      "Grover raises €37M Series A to offer latest tech products as a subscription\n",
      " github    : 2.01788429877e-06\n",
      " nytimes   : 0.00564260361716\n",
      " techcrunch: 0.99435544014\n",
      "\n",
      "Tech companies can now bid on the Pentagon’s $10B cloud contract\n",
      " github    : 0.00708839157596\n",
      " nytimes   : 0.0283307153732\n",
      " techcrunch: 0.964580893517\n",
      "\n",
      "‘Lopping,’ ‘Tips’ and the ‘Z-List’: Bias Lawsuit Explores Harvard’s Admissions\n",
      " github    : 0.0764058530331\n",
      " nytimes   : 0.224069595337\n",
      " techcrunch: 0.699524581432\n",
      "\n",
      "A $3B Plan to Turn Hoover Dam into a Giant Battery\n",
      " github    : 0.0555238202214\n",
      " nytimes   : 0.270869225264\n",
      " techcrunch: 0.673606932163\n",
      "\n",
      "A MeToo Reckoning in China’s Workplace Amid Wave of Accusations\n",
      " github    : 0.178793072701\n",
      " nytimes   : 0.382247179747\n",
      " techcrunch: 0.438959777355\n",
      "\n",
      "Show HN: Moon – 3kb JavaScript UI compiler\n",
      " github    : 0.999206602573\n",
      " nytimes   : 2.54288829638e-06\n",
      " techcrunch: 0.000790925638285\n",
      "\n",
      "Show HN: Hello, a CLI tool for managing social media\n",
      " github    : 0.00924264825881\n",
      " nytimes   : 0.0367251560092\n",
      " techcrunch: 0.954032242298\n",
      "\n",
      "Firefox Nightly added support for time-travel debugging\n",
      " github    : 0.758086919785\n",
      " nytimes   : 0.00994634069502\n",
      " techcrunch: 0.231966733932\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "# JSON format the requests\n",
    "requests = techcrunch+nytimes+github\n",
    "request_data = {'instances': requests}\n",
    "\n",
    "# Authenticate and call CMLE prediction API \n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'txtcls', 'v1_finetune_native')\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "\n",
    "# Format and print response\n",
    "for i in xrange(len(requests)):\n",
    "  print('\\n{}'.format(requests[i]))\n",
    "  print(' github    : {}'.format(response['predictions'][i]['dense_1'][0]))\n",
    "  print(' nytimes   : {}'.format(response['predictions'][i]['dense_1'][1]))\n",
    "  print(' techcrunch: {}'.format(response['predictions'][i]['dense_1'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Issues to vet\n",
    "- Is the vocab.txt embedded with the model? (try deleting GCS vocab.txt, does serving still work?)\n",
    "- Is all the code the same except the serving_input_fn? If so no need for two versions! Just talk about why you need the serving_input_fn to be different from the get go.\n",
    "- Does distributed training work on CMLE?\n",
    "- Padwords and unknown tokens have the same representation. Is this a significant issue? Could add a mapping for the padword to remedy\n",
    "- Training/serving skew (redo input fn after all so padding)\n",
    "- Are you using only the top_N words? (test in sandbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### References\n",
    "- This implementation is based on code from Google's 'eng-edu' team: https://github.com/google/eng-edu/tree/master/ml/guides/text_classification.\n",
    "- See the full text classification tutorial at: https://developers.google.com/machine-learning/guides/text-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
