{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Estimator and Experiment\n",
    "\n",
    "Demonstrates how to implement different image models on MNIST using Estimator/Experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "print mnist.train.images.shape\n",
    "print mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_model(img):\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) # flattened\n",
    "  #W = tf.Variable(tf.zeros([HEIGHT*WIDTH, NCLASSES]))\n",
    "  #b = tf.Variable(tf.zeros([NCLASSES]))\n",
    "  W = tf.Variable(tf.truncated_normal([HEIGHT*WIDTH, NCLASSES], stddev=0.1))\n",
    "  b = tf.Variable(tf.truncated_normal([NCLASSES], stddev=0.1))\n",
    "  ylogits = tf.matmul(X, W) + b\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the harness\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_train_input_fn(mnist):\n",
    "  def input_fn():\n",
    "    features, labels = tf.train.shuffle_batch([tf.constant(mnist.train.images), tf.constant(mnist.train.labels)],\n",
    "                                            batch_size=100, capacity=5000, min_after_dequeue=2000, enqueue_many=True)\n",
    "    features = {'image': features}\n",
    "    return features, labels\n",
    "  return input_fn\n",
    "\n",
    "def make_eval_input_fn(mnist):\n",
    "  def input_fn():\n",
    "    features, labels = tf.constant(mnist.test.images), tf.constant(mnist.test.labels)\n",
    "    features = {'image': features}\n",
    "    return features, labels\n",
    "  return input_fn\n",
    "\n",
    "def serving_input_fn():\n",
    "    inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "    features = inputs # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could have simply used a LinearClassifier, but later on, I will not want to use different models, and so let's write a custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  ylogits, nclasses = linear_model(features['image'])\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ylogits, labels=tf.one_hot(labels, nclasses)))\n",
    "    evalmetrics =  {'accuracy': tf.metrics.accuracy(classes, labels)}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                                 learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    " \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=evalmetrics,\n",
    "        export_outputs={'classes': tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classes\": classes})}\n",
    "    )\n",
    "\n",
    "def create_custom_estimator(output_dir, hparams):\n",
    "  training_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=None,\n",
    "                                               save_checkpoints_steps=hparams['train_steps']/5)\n",
    "  return tf.estimator.Estimator(model_fn=image_classifier, model_dir=output_dir, \n",
    "                                config=training_config, params=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment is the class that does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_experiment_fn(output_dir, data_dir, hparams):\n",
    "  def experiment_fn(output_dir):\n",
    "    mnist = input_data.read_data_sets(data_dir, reshape=False)  \n",
    "    return tf.contrib.learn.Experiment(\n",
    "      estimator=create_custom_estimator(output_dir, hparams),\n",
    "      train_input_fn=make_train_input_fn(mnist),\n",
    "      eval_input_fn=make_eval_input_fn(mnist),\n",
    "      train_steps=hparams['train_steps'],\n",
    "      eval_steps=1,\n",
    "      min_eval_frequency=min(100,hparams['train_steps']/10),\n",
    "      export_strategies=tf.contrib.learn.utils.saved_model_export_utils.make_export_strategy(serving_input_fn=serving_input_fn)\n",
    "    )\n",
    "  return experiment_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir='mnist/learned'\n",
    "hparams = {'train_steps': 100, 'learning_rate': 0.01}\n",
    "tf.contrib.learn.learn_runner.run(make_experiment_fn(output_dir, 'mnist/data', hparams), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Let's run it as Python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "rm -rf mnistmodel.tar.gz mnist_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mnistmodel\n",
    "python -m trainer.task \\\n",
    "   --output_dir=${PWD}/mnist_trained \\\n",
    "   --train_steps=100 --learning_rate=0.01 --job-dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it on ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "BUCKET=cloud-training-demos-ml\n",
    "REGION=us-central1\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained\n",
    "JOBNAME=mnist_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/mnistmodel/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC_GPU \\\n",
    "   -- \\\n",
    "   --train_steps=100 --learning_rate=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
