{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Serving embeddings </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> How to create a custom embedding as part of a regression/classification model\n",
    "<li> Different ways of representing categorical variables\n",
    "<li> How to serve out the embedding, as well as the original model \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "The problem is to estimate demand for bicycles at different rental stations in New York City.  The necessary data is in BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "#standardsql\n",
    "WITH bicycle_rentals AS (\n",
    "  SELECT\n",
    "    COUNT(starttime) as num_trips,\n",
    "    EXTRACT(DATE from starttime) as trip_date,\n",
    "    MAX(EXTRACT(DAYOFWEEK from starttime)) as day_of_week,\n",
    "    start_station_id\n",
    "  FROM `bigquery-public-data.new_york.citibike_trips`\n",
    "  GROUP BY trip_date, start_station_id\n",
    "),\n",
    "\n",
    "rainy_days AS\n",
    "(\n",
    "SELECT\n",
    "  date,\n",
    "  (MAX(prcp) > 5) AS rainy\n",
    "FROM (\n",
    "  SELECT\n",
    "    wx.date AS date,\n",
    "    IF (wx.element = 'PRCP', wx.value/10, NULL) AS prcp\n",
    "  FROM\n",
    "    `bigquery-public-data.ghcn_d.ghcnd_2016` AS wx\n",
    "  WHERE\n",
    "    wx.id = 'USW00094728'\n",
    ")\n",
    "GROUP BY\n",
    "  date\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  num_trips,\n",
    "  day_of_week,\n",
    "  start_station_id,\n",
    "  rainy\n",
    "FROM bicycle_rentals AS bk\n",
    "JOIN rainy_days AS wx\n",
    "ON wx.date = bk.trip_date\n",
    "\"\"\"\n",
    "import google.datalab.bigquery as bq\n",
    "df = bq.Query(query).execute().result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>rainy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120701</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102674</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>384</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83688</th>\n",
       "      <td>262</td>\n",
       "      <td>5</td>\n",
       "      <td>388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31810</th>\n",
       "      <td>269</td>\n",
       "      <td>2</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72086</th>\n",
       "      <td>371</td>\n",
       "      <td>4</td>\n",
       "      <td>497</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_trips  day_of_week  start_station_id  rainy\n",
       "120701         27            7               364  False\n",
       "102674         15            6               384  False\n",
       "83688         262            5               388  False\n",
       "31810         269            2               459  False\n",
       "72086         371            4               497  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the dataframe to make it easier to split into train/eval later\n",
    "df = df.sample(frac=1.0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Let's build a model to predict the number of trips that start at each station, given that we know the day of the week and whether it is a rainy day.\n",
    "\n",
    "Inputs to the model:\n",
    "* day of week (integerized, since it is 1-7)\n",
    "* station id (hash buckets, since we don't know full vocabulary. The dataset has about 650 unique values. we'll use a much larger hash bucket size, but then embed it into a lower dimension)\n",
    "* rainy (true/false)\n",
    "\n",
    "Label:\n",
    "* num_trips\n",
    "\n",
    "By embedding the station id into just 2 dimensions, we will also get to learn which stations are like each other, at least in the context of rainy-day-rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data type\n",
    "\n",
    "Let's change the Pandas data types to more efficient (for TensorFlow) forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_trips           int64\n",
       "day_of_week         int64\n",
       "start_station_id    int64\n",
       "rainy                bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_trips           float32\n",
       "day_of_week           int32\n",
       "start_station_id      int32\n",
       "rainy                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = df.astype({'num_trips': np.float32, 'day_of_week': np.int32, 'start_station_id': np.int32, 'rainy': str})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the label to make it easier to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['num_trips'] = df['num_trips'] / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 104148 training examples and 26037 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "num_train = (int) (len(df) * 0.8)\n",
    "train_df = df.iloc[:num_train]\n",
    "eval_df  = df.iloc[num_train:]\n",
    "print(\"Split into {} training examples and {} evaluation examples\".format(len(train_df), len(eval_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_trips</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>rainy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120701</th>\n",
       "      <td>0.027</td>\n",
       "      <td>7</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102674</th>\n",
       "      <td>0.015</td>\n",
       "      <td>6</td>\n",
       "      <td>384</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83688</th>\n",
       "      <td>0.262</td>\n",
       "      <td>5</td>\n",
       "      <td>388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31810</th>\n",
       "      <td>0.269</td>\n",
       "      <td>2</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72086</th>\n",
       "      <td>0.371</td>\n",
       "      <td>4</td>\n",
       "      <td>497</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_trips  day_of_week  start_station_id  rainy\n",
       "120701      0.027            7               364  False\n",
       "102674      0.015            6               384  False\n",
       "83688       0.262            5               388  False\n",
       "31810       0.269            2               459  False\n",
       "72086       0.371            4               497  False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Creating an Estimator model </h2>\n",
    "\n",
    "Pretty minimal, but it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd520c87cd0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './model_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 10 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.244965, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.8244219.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-09-20:38:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-09-20:38:00\n",
      "INFO:tensorflow:Saving dict for global step 10: average_loss = 0.005806471, global_step = 10, loss = 0.7410936\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'rainy': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'day_of_week': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'start_station_id': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'rainy': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'day_of_week': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'start_station_id': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-10\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./model_trained/export/exporter/temp-1531168681/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def make_input_fn(indf, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    indf,\n",
    "    indf['num_trips'],\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True)\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      'day_of_week': tf.placeholder(tf.int32, [None]),\n",
    "      'start_station_id': tf.placeholder(tf.int32, [None]),\n",
    "      'rainy': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "  \n",
    "def train_and_evaluate(output_dir, nsteps):\n",
    "  station_embed = tf.feature_column.embedding_column(\n",
    "      tf.feature_column.categorical_column_with_hash_bucket('start_station_id', 5000, tf.int32), 2)\n",
    "  feature_cols = [\n",
    "    tf.feature_column.categorical_column_with_identity('day_of_week', num_buckets = 8),\n",
    "    station_embed,\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('rainy', ['false', 'true'])\n",
    "  ]\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = feature_cols)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = make_input_fn(train_df, None),\n",
    "                       max_steps = nsteps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = make_input_fn(eval_df, 1),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "  \n",
    "import shutil\n",
    "OUTDIR='./model_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True)\n",
    "train_and_evaluate(OUTDIR, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.json\n"
     ]
    }
   ],
   "source": [
    "%writefile test.json\n",
    "{\"day_of_week\": 3, \"start_station_id\": 384, \"rainy\": \"false\"}\n",
    "{\"day_of_week\": 4, \"start_station_id\": 384, \"rainy\": \"true\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "[0.062436774373054504]\n",
      "[0.08942072093486786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-07-09 20:38:11.170549: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "EXPORTDIR=./model_trained/export/exporter/\n",
    "MODELDIR=$(ls $EXPORTDIR | tail -1)\n",
    "gcloud ml-engine local predict --model-dir=${EXPORTDIR}/${MODELDIR} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving out the embedding also\n",
    "\n",
    "To serve out the embedding, we need to use a model function (a custom estimator) so that we have access to output_alternates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd51f8580d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './model_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 10 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.14085387, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./model_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.14263466.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-13:21:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-13:21:32\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 0.13780683, rmse = 0.37127492\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predict_export_outputs']\n",
      "INFO:tensorflow:Restoring parameters from ./model_trained/model.ckpt-10\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./model_trained/export/exporter/temp-1531228892/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def make_input_fn(indf, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    indf,\n",
    "    indf['num_trips'],\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True)\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      'day_of_week': tf.placeholder(tf.int32, [None]),\n",
    "      'start_station_id': tf.placeholder(tf.int32, [None]),\n",
    "      'rainy': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "  # linear model\n",
    "  station_col = tf.feature_column.categorical_column_with_hash_bucket('start_station_id', 5000, tf.int32)\n",
    "  station_embed = tf.feature_column.embedding_column(station_col, 2)  # embed dimension\n",
    "  embed_layer = tf.feature_column.input_layer(features, station_embed)\n",
    "  \n",
    "  cat_cols = [\n",
    "    tf.feature_column.categorical_column_with_identity('day_of_week', num_buckets = 8),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('rainy', ['false', 'true'])\n",
    "  ]\n",
    "  cat_cols = [tf.feature_column.indicator_column(col) for col in cat_cols]\n",
    "  other_inputs = tf.feature_column.input_layer(features, cat_cols)\n",
    "  \n",
    "  all_inputs = tf.concat([embed_layer, other_inputs], axis=1)\n",
    "  predictions = tf.layers.dense(all_inputs, 1)  # linear model\n",
    "  \n",
    "  # 2. Loss function, training/eval ops\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        labels = tf.expand_dims(labels, -1)\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step(),\n",
    "            learning_rate = 0.01,\n",
    "            optimizer = \"SGD\")\n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        }\n",
    "  else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "  \n",
    "  # 3. Create predictions\n",
    "  predictions_dict = {\n",
    "    \"predicted\": predictions,\n",
    "    \"station_embed\": embed_layer\n",
    "  }\n",
    "    \n",
    "  # 4. Create export outputs\n",
    "  export_outputs = {\n",
    "    \"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)\n",
    "  }\n",
    "\n",
    "  # 5. Return EstimatorSpec\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops,\n",
    "        export_outputs = export_outputs)\n",
    "\n",
    "def train_and_evaluate(output_dir, nsteps):\n",
    "  estimator = tf.estimator.Estimator(\n",
    "                       model_fn = model_fn,\n",
    "                       model_dir = output_dir)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = make_input_fn(train_df, None),\n",
    "                       max_steps = nsteps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = make_input_fn(eval_df, 1),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "  \n",
    "import shutil\n",
    "OUTDIR='./model_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True)\n",
    "train_and_evaluate(OUTDIR, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED               STATION_EMBED\n",
      "[-0.13162994384765625]  [-0.5743858218193054, -0.2299821525812149]\n",
      "[0.1520620435476303]    [-0.5743858218193054, -0.2299821525812149]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-07-10 13:21:40.623204: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "EXPORTDIR=./model_trained/export/exporter/\n",
    "MODELDIR=$(ls $EXPORTDIR | tail -1)\n",
    "gcloud ml-engine local predict --model-dir=${EXPORTDIR}/${MODELDIR} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
