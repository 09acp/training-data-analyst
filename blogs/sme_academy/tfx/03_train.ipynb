{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfcSMZEIFA_l"
   },
   "source": [
    "# ML with TensorFlow Extended (TFX) -- Part 3\n",
    "The puprpose of this tutorial is to show how to do end-to-end ML with TFX libraries on Google Cloud Platform. This tutorial covers:\n",
    "1. Data analysis and schema generation with **TF Data Validation**.\n",
    "2. Data preprocessing with **TF Transform**.\n",
    "3. Model training with **TF Estimator**.\n",
    "4. Model evaluation with **TF Model Analysis**.\n",
    "\n",
    "This notebook has been tested in Jupyter on the Deep Learning VM.\n",
    "\n",
    "## 0. Setup Python and Cloud environment\n",
    "\n",
    "Install libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkkjO6RyH5UP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade tensorflow_data_validation tensorflow_model_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tornado version: 6.0.2\n",
      "Python version: 3.5.3\n",
      "TF version: 1.13.1\n",
      "TFT version: 0.13.0\n",
      "TFDV version: 0.13.1\n",
      "Apache Beam version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_transform as tft\n",
    "import tornado\n",
    "\n",
    "print('tornado version: {}'.format(tornado.version))\n",
    "print('Python version: {}'.format(platform.python_version()))\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TFT version: {}'.format(tft.__version__))\n",
    "print('TFDV version: {}'.format(tfdv.__version__))\n",
    "print('Apache Beam version: {}'.format(beam.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'cloud-training-demos'    # Replace with your PROJECT\n",
    "BUCKET = 'cloud-training-demos-ml'  # Replace with your BUCKET\n",
    "REGION = 'us-central1'              # Choose an available region for Cloud MLE\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n",
      "Updated property [ml_engine/local_python].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION\n",
    "\n",
    "## ensure we predict locally with our current Python environment\n",
    "gcloud config set ml_engine/local_python `which python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img valign=\"middle\" src=\"images/tfx.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9u699PmHJXU"
   },
   "source": [
    "### UCI Adult Dataset: https://archive.ics.uci.edu/ml/datasets/adult\n",
    "Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='gs://cloud-samples-data/ml-engine/census/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ksuSTsysHfZV",
    "outputId": "87adfbf0-be77-4d81-9162-5a2f9feffd90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3974304  2018-05-10T22:21:14Z  gs://cloud-samples-data/ml-engine/census/data/adult.data.csv\n",
      "TOTAL: 1 objects, 3974304 bytes (3.79 MiB)\n",
      "   1986465  2018-05-10T22:21:14Z  gs://cloud-samples-data/ml-engine/census/data/adult.test.csv\n",
      "TOTAL: 1 objects, 1986465 bytes (1.89 MiB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR, 'adult.data.csv')\n",
    "EVAL_DATA_FILE = os.path.join(DATA_DIR, 'adult.test.csv')\n",
    "!gsutil ls -l $TRAIN_DATA_FILE\n",
    "!gsutil ls -l $EVAL_DATA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "               'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "               'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "               'native_country', 'income_bracket']\n",
    "\n",
    "TARGET_FEATURE_NAME = 'income_bracket'\n",
    "TARGET_LABELS = [' <=50K', ' >50K']\n",
    "WEIGHT_COLUMN_NAME = 'fnlwgt'\n",
    "\n",
    "RAW_SCHEMA_LOCATION = 'raw_schema.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qNjgoalG0Xu"
   },
   "source": [
    "## 3. Model Training\n",
    "For training the model, we use [TF Estimators](https://www.tensorflow.org/guide/estimators) APIs to train a premade DNNClassifier. We perform the following:\n",
    "1. Load the **transform schema**\n",
    "2. Use the transform schema to parse TFRecords in **input_fn**\n",
    "3. Use the transform schema to create **feature columns**\n",
    "4. Create a premade **DNNClassifier**\n",
    "5. **Train** the model\n",
    "6. Implement the **serving_input_fn** and apply the **transform logic**\n",
    "7. **Export** and test the saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4eLEbV42XEz"
   },
   "source": [
    "### 3.1 Load transform output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/census/tfx/transform/\n",
      "gs://cloud-training-demos-ml/census/tfx/transform/transform_fn/\n",
      "gs://cloud-training-demos-ml/census/tfx/transform/transformed_metadata/\n",
      "gs://cloud-training-demos-ml/census/tfx/transformed/eval-00000-of-00001.tfrecords\n",
      "gs://cloud-training-demos-ml/census/tfx/transformed/train-00000-of-00001.tfrecords\n"
     ]
    }
   ],
   "source": [
    "PREPROC_OUTPUT_DIR = 'gs://{}/census/tfx'.format(BUCKET)  # from 02_transform.ipynb\n",
    "TRANSFORM_ARTIFACTS_DIR = os.path.join(PREPROC_OUTPUT_DIR,'transform')\n",
    "TRANSFORMED_DATA_DIR = os.path.join(PREPROC_OUTPUT_DIR,'transformed')\n",
    "!gsutil ls $TRANSFORM_ARTIFACTS_DIR\n",
    "!gsutil ls $TRANSFORMED_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR_d4-kBG0hI"
   },
   "outputs": [],
   "source": [
    "transform_output = tft.TFTransformOutput(TRANSFORM_ARTIFACTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxt31_6M3dbl"
   },
   "source": [
    "### 3.2 TFRecords Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQqf9dGF3dEe"
   },
   "outputs": [],
   "source": [
    "def make_input_fn(tfrecords_files, \n",
    "  batch_size, num_epochs=1, shuffle=False):\n",
    "\n",
    "  def input_fn():\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "      file_pattern=tfrecords_files,\n",
    "      batch_size=batch_size,\n",
    "      features=transform_output.transformed_feature_spec(),\n",
    "      label_key=TARGET_FEATURE_NAME,\n",
    "      reader=tf.data.TFRecordDataset,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({occupation_integerized: (?, 1), education_integerized: (?, 1), workclass_integerized: (?, 1), age_bucketized: (?, 1), age_scaled: (?, 1), education_num_scaled: (?, 1), marital_status_integerized: (?, 1), hours_per_week_scaled: (?, 1), relationship_integerized: (?, 1), gender_integerized: (?, 1), capital_loss_scaled: (?, 1), native_country_integerized: (?, 1), race_integerized: (?, 1), fnlwgt_scaled: (?, 1), capital_gain_scaled: (?, 1)}, (?, 1)), types: ({occupation_integerized: tf.int64, education_integerized: tf.int64, workclass_integerized: tf.int64, age_bucketized: tf.int64, age_scaled: tf.float32, education_num_scaled: tf.float32, marital_status_integerized: tf.int64, hours_per_week_scaled: tf.float32, relationship_integerized: tf.int64, gender_integerized: tf.int64, capital_loss_scaled: tf.float32, native_country_integerized: tf.int64, race_integerized: tf.int64, fnlwgt_scaled: tf.float32, capital_gain_scaled: tf.float32}, tf.string)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_fn(TRANSFORMED_DATA_DIR+'/train*.tfrecords', 2, shuffle=False)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgQtTPiN4Td0"
   },
   "source": [
    "### 3.3 Create feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzP3BUnU4bE5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def create_feature_columns():\n",
    "\n",
    "  feature_columns = []\n",
    "  transformed_features = transform_output.transformed_metadata.schema._schema_proto.feature\n",
    "\n",
    "  for feature in transformed_features:\n",
    "\n",
    "    if feature.name in [TARGET_FEATURE_NAME, WEIGHT_COLUMN_NAME]:\n",
    "      continue\n",
    "\n",
    "    if hasattr(feature, 'int_domain') and feature.int_domain.is_categorical:\n",
    "      vocab_size = feature.int_domain.max + 1\n",
    "      feature_columns.append(\n",
    "        tf.feature_column.embedding_column(\n",
    "          tf.feature_column.categorical_column_with_identity(\n",
    "            feature.name, num_buckets=vocab_size),\n",
    "            dimension = int(math.sqrt(vocab_size))))\n",
    "    else:\n",
    "      feature_columns.append(\n",
    "        tf.feature_column.numeric_column(feature.name))\n",
    "\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "wAttQuXh-ZXR",
    "outputId": "4f998a45-7c41-460c-8d66-e59bf18a507b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='age_bucketized', number_buckets=5, default_value=None), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d4e0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " NumericColumn(key='age_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='capital_gain_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='capital_loss_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='education_integerized', number_buckets=16, default_value=None), dimension=4, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d390>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " NumericColumn(key='education_num_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fnlwgt_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='gender_integerized', number_buckets=2, default_value=None), dimension=1, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d4a8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " NumericColumn(key='hours_per_week_scaled', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='marital_status_integerized', number_buckets=7, default_value=None), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d2b0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='native_country_integerized', number_buckets=42, default_value=None), dimension=6, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d978>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='occupation_integerized', number_buckets=15, default_value=None), dimension=3, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d940>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='race_integerized', number_buckets=5, default_value=None), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d828>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='relationship_integerized', number_buckets=6, default_value=None), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19d630>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " EmbeddingColumn(categorical_column=IdentityCategoricalColumn(key='workclass_integerized', number_buckets=9, default_value=None), dimension=3, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7effcf19dd30>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_feature_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cr4iLJtK4bgv"
   },
   "source": [
    "### 3.4 Instantiate and Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKAGwUgP4Tkf"
   },
   "outputs": [],
   "source": [
    "def create_estimator(params, run_config):\n",
    "    \n",
    "  feature_columns = create_feature_columns()\n",
    "\n",
    "  estimator = tf.estimator.DNNClassifier(\n",
    "    #weight_column=WEIGHT_COLUMN_NAME,\n",
    "    label_vocabulary=TARGET_LABELS,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=params.hidden_units,\n",
    "    config=run_config\n",
    "  )\n",
    "\n",
    "  return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZIyscv84nXF"
   },
   "source": [
    "### 3.5 Implement train and evaluate experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3zLhoZj4nd4"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def run_experiment(estimator, params, run_config, resume=False):\n",
    "  \n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  if not resume: \n",
    "    if tf.gfile.Exists(run_config.model_dir):\n",
    "      print(\"Removing previous artifacts...\")\n",
    "      tf.gfile.DeleteRecursively(run_config.model_dir)\n",
    "  else:\n",
    "    print(\"Resuming training...\")\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "      input_fn = make_input_fn(\n",
    "          TRANSFORMED_DATA_DIR+'/train*.tfrecords',\n",
    "          batch_size=params.batch_size,\n",
    "          num_epochs=None,\n",
    "          shuffle=True\n",
    "      ),\n",
    "      max_steps=params.max_steps\n",
    "  )\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "      input_fn = make_input_fn(\n",
    "          TRANSFORMED_DATA_DIR+'/eval*.tfrecords',\n",
    "          batch_size=params.batch_size,     \n",
    "      ),\n",
    "      start_delay_secs=0,\n",
    "      throttle_secs=0,\n",
    "      steps=None\n",
    "  )\n",
    "  \n",
    "  time_start = datetime.utcnow() \n",
    "  print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "  print(\".......................................\")\n",
    "  \n",
    "  tf.estimator.train_and_evaluate(\n",
    "    estimator=estimator,\n",
    "    train_spec=train_spec, \n",
    "    eval_spec=eval_spec)\n",
    "\n",
    "  time_end = datetime.utcnow() \n",
    "  print(\".......................................\")\n",
    "  print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "  print(\"\")\n",
    "  \n",
    "  time_elapsed = time_end - time_start\n",
    "  print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1VBm6Bo4ntU"
   },
   "source": [
    "### 3.5 Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mHEsbh94n0V"
   },
   "outputs": [],
   "source": [
    "MODELS_LOCATION = 'models/census'\n",
    "MODEL_NAME = 'dnn_classifier'\n",
    "model_dir = os.path.join(MODELS_LOCATION, MODEL_NAME)\n",
    "os.environ['MODEL_DIR'] = model_dir\n",
    "\n",
    "params = tf.contrib.training.HParams()\n",
    "params.hidden_units = [128, 64]\n",
    "params.dropout = 0.15\n",
    "params.batch_size =  128\n",
    "params.max_steps = 1000\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    tf_random_seed=19831006,\n",
    "    save_checkpoints_steps=200, \n",
    "    keep_checkpoint_max=3, \n",
    "    model_dir=model_dir,\n",
    "    log_step_count_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4950
    },
    "colab_type": "code",
    "id": "9yMxrzCE5tWw",
    "outputId": "25c1dead-69c2-4b14-e987-bf21b056559b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_is_chief': True, '_eval_distribute': None, '_service': None, '_log_step_count_steps': 10, '_keep_checkpoint_max': 3, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff92e009e8>, '_save_checkpoints_secs': None, '_task_id': 0, '_save_checkpoints_steps': 200, '_save_summary_steps': 100, '_master': '', '_protocol': None, '_model_dir': 'models/census/dnn_classifier', '_task_type': 'worker', '_train_distribute': None, '_tf_random_seed': 19831006, '_global_id_in_cluster': 0, '_evaluation_master': '', '_num_worker_replicas': 1, '_experimental_distribute': None}\n",
      "Removing previous artifacts...\n",
      "Experiment started at 22:39:44\n",
      ".......................................\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 200 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/census/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 90.49696, step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.70632\n",
      "INFO:tensorflow:loss = 46.47725, step = 11 (2.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.809\n",
      "INFO:tensorflow:loss = 36.163063, step = 21 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.977\n",
      "INFO:tensorflow:loss = 48.27557, step = 31 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.31\n",
      "INFO:tensorflow:loss = 36.365826, step = 41 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.611\n",
      "INFO:tensorflow:loss = 44.03159, step = 51 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.151\n",
      "INFO:tensorflow:loss = 43.51145, step = 61 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.664\n",
      "INFO:tensorflow:loss = 48.599022, step = 71 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.893\n",
      "INFO:tensorflow:loss = 44.310883, step = 81 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.028\n",
      "INFO:tensorflow:loss = 38.07524, step = 91 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.526\n",
      "INFO:tensorflow:loss = 40.676704, step = 101 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.776\n",
      "INFO:tensorflow:loss = 39.86065, step = 111 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.4401\n",
      "INFO:tensorflow:loss = 41.039806, step = 121 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.823\n",
      "INFO:tensorflow:loss = 42.00899, step = 131 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.54\n",
      "INFO:tensorflow:loss = 61.24848, step = 141 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.635\n",
      "INFO:tensorflow:loss = 34.58851, step = 151 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.007\n",
      "INFO:tensorflow:loss = 36.94484, step = 161 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.214\n",
      "INFO:tensorflow:loss = 44.56858, step = 171 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.995\n",
      "INFO:tensorflow:loss = 43.470177, step = 181 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.179\n",
      "INFO:tensorflow:loss = 41.534306, step = 191 (0.083 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into models/census/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T22:39:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/census/dnn_classifier/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-22:40:02\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.85532624, accuracy_baseline = 0.7637916, auc = 0.9094383, auc_precision_recall = 0.7762666, average_loss = 0.3102352, global_step = 200, label/mean = 0.23620838, loss = 39.453194, precision = 0.73093617, prediction/mean = 0.24169664, recall = 0.61326396\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: models/census/dnn_classifier/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 1.49388\n",
      "INFO:tensorflow:loss = 31.56647, step = 201 (6.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8698\n",
      "INFO:tensorflow:loss = 38.640972, step = 211 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.052\n",
      "INFO:tensorflow:loss = 39.929794, step = 221 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.984\n",
      "INFO:tensorflow:loss = 40.153694, step = 231 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.418\n",
      "INFO:tensorflow:loss = 37.29897, step = 241 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.246\n",
      "INFO:tensorflow:loss = 32.056267, step = 251 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.794\n",
      "INFO:tensorflow:loss = 49.42749, step = 261 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.054\n",
      "INFO:tensorflow:loss = 35.967567, step = 271 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.588\n",
      "INFO:tensorflow:loss = 54.527817, step = 281 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.629\n",
      "INFO:tensorflow:loss = 40.01611, step = 291 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.698\n",
      "INFO:tensorflow:loss = 47.712845, step = 301 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.425\n",
      "INFO:tensorflow:loss = 46.177048, step = 311 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.143\n",
      "INFO:tensorflow:loss = 28.467686, step = 321 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.226\n",
      "INFO:tensorflow:loss = 43.187275, step = 331 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.629\n",
      "INFO:tensorflow:loss = 47.516663, step = 341 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.685\n",
      "INFO:tensorflow:loss = 37.669903, step = 351 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.083\n",
      "INFO:tensorflow:loss = 46.248108, step = 361 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.234\n",
      "INFO:tensorflow:loss = 49.497635, step = 371 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.102\n",
      "INFO:tensorflow:loss = 38.665752, step = 381 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.06\n",
      "INFO:tensorflow:loss = 42.867867, step = 391 (0.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into models/census/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T22:40:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/census/dnn_classifier/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-22:40:09\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.8572306, accuracy_baseline = 0.7637916, auc = 0.91051465, auc_precision_recall = 0.7781231, average_loss = 0.3095975, global_step = 400, label/mean = 0.23620838, loss = 39.372093, precision = 0.72817284, prediction/mean = 0.24063568, recall = 0.6312094\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: models/census/dnn_classifier/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 1.63469\n",
      "INFO:tensorflow:loss = 31.822748, step = 401 (6.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.4253\n",
      "INFO:tensorflow:loss = 40.292305, step = 411 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.183\n",
      "INFO:tensorflow:loss = 42.67212, step = 421 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.87\n",
      "INFO:tensorflow:loss = 36.28701, step = 431 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.951\n",
      "INFO:tensorflow:loss = 47.59772, step = 441 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.766\n",
      "INFO:tensorflow:loss = 37.01126, step = 451 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.624\n",
      "INFO:tensorflow:loss = 27.387407, step = 461 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.949\n",
      "INFO:tensorflow:loss = 32.690403, step = 471 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.357\n",
      "INFO:tensorflow:loss = 35.260857, step = 481 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.225\n",
      "INFO:tensorflow:loss = 27.862728, step = 491 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.692\n",
      "INFO:tensorflow:loss = 34.058964, step = 501 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.673\n",
      "INFO:tensorflow:loss = 33.221336, step = 511 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.086\n",
      "INFO:tensorflow:loss = 41.64991, step = 521 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.733\n",
      "INFO:tensorflow:loss = 38.367233, step = 531 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.04\n",
      "INFO:tensorflow:loss = 41.68377, step = 541 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.377\n",
      "INFO:tensorflow:loss = 34.6053, step = 551 (0.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.777\n",
      "INFO:tensorflow:loss = 64.194786, step = 561 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.009\n",
      "INFO:tensorflow:loss = 40.330574, step = 571 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.335\n",
      "INFO:tensorflow:loss = 24.20507, step = 581 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.654\n",
      "INFO:tensorflow:loss = 31.416876, step = 591 (0.060 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into models/census/dnn_classifier/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T22:40:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/census/dnn_classifier/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-22:40:17\n",
      "INFO:tensorflow:Saving dict for global step 600: accuracy = 0.8580907, accuracy_baseline = 0.7637916, auc = 0.91118497, auc_precision_recall = 0.7798611, average_loss = 0.30921724, global_step = 600, label/mean = 0.23620838, loss = 39.32374, precision = 0.7190979, prediction/mean = 0.2547941, recall = 0.6551365\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: models/census/dnn_classifier/model.ckpt-600\n",
      "INFO:tensorflow:global_step/sec: 1.66991\n",
      "INFO:tensorflow:loss = 38.014114, step = 601 (5.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.2887\n",
      "INFO:tensorflow:loss = 36.364815, step = 611 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.391\n",
      "INFO:tensorflow:loss = 35.590775, step = 621 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.179\n",
      "INFO:tensorflow:loss = 40.29273, step = 631 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.483\n",
      "INFO:tensorflow:loss = 34.73351, step = 641 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.862\n",
      "INFO:tensorflow:loss = 36.889305, step = 651 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.486\n",
      "INFO:tensorflow:loss = 37.931717, step = 661 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.703\n",
      "INFO:tensorflow:loss = 23.630821, step = 671 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.44\n",
      "INFO:tensorflow:loss = 42.33938, step = 681 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.873\n",
      "INFO:tensorflow:loss = 36.828926, step = 691 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.773\n",
      "INFO:tensorflow:loss = 36.044613, step = 701 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.488\n",
      "INFO:tensorflow:loss = 39.442417, step = 711 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.896\n",
      "INFO:tensorflow:loss = 28.84632, step = 721 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.855\n",
      "INFO:tensorflow:loss = 47.697746, step = 731 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.626\n",
      "INFO:tensorflow:loss = 32.973305, step = 741 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.951\n",
      "INFO:tensorflow:loss = 44.8204, step = 751 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.122\n",
      "INFO:tensorflow:loss = 47.058685, step = 761 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.611\n",
      "INFO:tensorflow:loss = 37.244984, step = 771 (0.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.174\n",
      "INFO:tensorflow:loss = 37.494835, step = 781 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.371\n",
      "INFO:tensorflow:loss = 48.677147, step = 791 (0.086 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into models/census/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T22:40:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/census/dnn_classifier/model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-22:40:24\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.8591965, accuracy_baseline = 0.7637916, auc = 0.91193736, auc_precision_recall = 0.78254956, average_loss = 0.30639818, global_step = 800, label/mean = 0.23620838, loss = 38.965233, precision = 0.75219226, prediction/mean = 0.23063305, recall = 0.6023407\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: models/census/dnn_classifier/model.ckpt-800\n",
      "INFO:tensorflow:global_step/sec: 1.74328\n",
      "INFO:tensorflow:loss = 31.515717, step = 801 (5.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.376\n",
      "INFO:tensorflow:loss = 37.685974, step = 811 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.13\n",
      "INFO:tensorflow:loss = 30.653223, step = 821 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.137\n",
      "INFO:tensorflow:loss = 40.425735, step = 831 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.068\n",
      "INFO:tensorflow:loss = 43.29048, step = 841 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.295\n",
      "INFO:tensorflow:loss = 38.11067, step = 851 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.367\n",
      "INFO:tensorflow:loss = 27.247074, step = 861 (0.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.885\n",
      "INFO:tensorflow:loss = 51.57692, step = 871 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.719\n",
      "INFO:tensorflow:loss = 30.031425, step = 881 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.561\n",
      "INFO:tensorflow:loss = 32.593887, step = 891 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.723\n",
      "INFO:tensorflow:loss = 36.50762, step = 901 (0.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.84\n",
      "INFO:tensorflow:loss = 30.233044, step = 911 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.439\n",
      "INFO:tensorflow:loss = 39.10984, step = 921 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.952\n",
      "INFO:tensorflow:loss = 45.617386, step = 931 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.156\n",
      "INFO:tensorflow:loss = 43.84748, step = 941 (0.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.919\n",
      "INFO:tensorflow:loss = 46.671825, step = 951 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.756\n",
      "INFO:tensorflow:loss = 23.627459, step = 961 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.091\n",
      "INFO:tensorflow:loss = 32.225105, step = 971 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.508\n",
      "INFO:tensorflow:loss = 34.216858, step = 981 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.998\n",
      "INFO:tensorflow:loss = 43.575584, step = 991 (0.062 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into models/census/dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T22:40:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/census/dnn_classifier/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-22:40:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8591965, accuracy_baseline = 0.7637916, auc = 0.9113077, auc_precision_recall = 0.7814753, average_loss = 0.3081054, global_step = 1000, label/mean = 0.23620838, loss = 39.182343, precision = 0.7404769, prediction/mean = 0.23050801, recall = 0.62184656\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: models/census/dnn_classifier/model.ckpt-1000\n",
      "INFO:tensorflow:Loss for final step: 35.735043.\n",
      ".......................................\n",
      "Experiment finished at 22:40:31\n",
      "\n",
      "Experiment elapsed time: 46.833022 seconds\n"
     ]
    }
   ],
   "source": [
    "estimator = create_estimator(params, run_config)\n",
    "run_experiment(estimator, params, run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pr-L_KM8LwmK"
   },
   "source": [
    "### 3.6 Export the model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBdB7mkvL43C"
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "def make_serving_input_receiver_fn():\n",
    "  from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "  source_raw_schema = tfdv.load_schema_text(RAW_SCHEMA_LOCATION)\n",
    "  raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "  raw_feature_spec.pop(TARGET_FEATURE_NAME)\n",
    "  if WEIGHT_COLUMN_NAME in raw_feature_spec:\n",
    "    raw_feature_spec.pop(WEIGHT_COLUMN_NAME)\n",
    "\n",
    "\n",
    "  # Create the interface for the serving function with the raw features\n",
    "  raw_features = tf.estimator.export.build_parsing_serving_input_receiver_fn(raw_feature_spec)().features\n",
    "\n",
    "  receiver_tensors = {feature: tf.placeholder(shape=[None], dtype=raw_features[feature].dtype) \n",
    "    for feature in raw_features\n",
    "  }\n",
    "\n",
    "  receiver_tensors_expanded = {tensor: tf.reshape(receiver_tensors[tensor], (-1, 1)) \n",
    "    for tensor in receiver_tensors\n",
    "  }\n",
    "\n",
    "  # Apply the transform function \n",
    "  transformed_features = transform_output.transform_raw_features(receiver_tensors_expanded)\n",
    "\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "    transformed_features, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "id": "_KcSJ6kEMG57",
    "outputId": "d0bcdb14-82ef-4b22-9484-90170f1b7984"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'models/census/dnn_classifier/export/1554158437'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dir = os.path.join(model_dir, 'export')\n",
    "\n",
    "if tf.gfile.Exists(export_dir):\n",
    "    tf.gfile.DeleteRecursively(export_dir)\n",
    "        \n",
    "estimator.export_savedmodel(\n",
    "    export_dir_base=export_dir,\n",
    "    serving_input_receiver_fn=make_serving_input_receiver_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1377
    },
    "colab_type": "code",
    "id": "XPFCTtSdQMd5",
    "outputId": "2ec32f67-47f5-4ef0-8a86-fe1797befdef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/census/dnn_classifier/export/1554158437\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['age'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_3:0\n",
      "    inputs['capital_gain'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_6:0\n",
      "    inputs['capital_loss'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_1:0\n",
      "    inputs['education'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_2:0\n",
      "    inputs['education_num'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_4:0\n",
      "    inputs['gender'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder:0\n",
      "    inputs['hours_per_week'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: Placeholder_12:0\n",
      "    inputs['marital_status'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_8:0\n",
      "    inputs['native_country'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_7:0\n",
      "    inputs['occupation'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_9:0\n",
      "    inputs['race'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_11:0\n",
      "    inputs['relationship'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_5:0\n",
      "    inputs['workclass'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: Placeholder_10:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['class_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 1)\n",
      "        name: dnn/head/predictions/ExpandDims:0\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 1)\n",
      "        name: dnn/head/predictions/class_string_lookup_Lookup:0\n",
      "    outputs['logistic'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: dnn/head/predictions/logistic:0\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: dnn/logits/BiasAdd:0\n",
      "    outputs['probabilities'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: dnn/head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "saved_models_base=${MODEL_DIR}/export/\n",
    "saved_model_dir=${MODEL_DIR}/export/$(ls ${saved_models_base} | tail -n 1)\n",
    "echo ${saved_model_dir}\n",
    "saved_model_cli show --dir=${saved_model_dir} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFQcy8QDQ6Ad"
   },
   "source": [
    "### 3.7 Try out saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "0tacIgD5Q6HB",
    "outputId": "133588d7-1d0b-4a9f-fd88-b79d096f55b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/census/dnn_classifier/export/1554158437\n",
      "\n",
      "{'gender': ['Male'], 'capital_loss': [0.0], 'education': ['Doctorate'], 'age': [34.0], 'education_num': [10.0], 'relationship': ['Husband'], 'capital_gain': [0.0], 'native_country': ['Mexico'], 'marital_status': ['Married-civ-spouse'], 'occupation': ['Prof-specialty'], 'workclass': ['Private'], 'race': ['White'], 'hours_per_week': [40.0]}\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'transform/transform/inputs/fnlwgt' with dtype int64 and shape [?,1]\n\t [[node transform/transform/inputs/fnlwgt (defined at <ipython-input-22-01faacbd3703>:9) ]]\n\nCaused by op 'transform/transform/inputs/fnlwgt', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-01faacbd3703>\", line 9, in <module>\n    signature_def_key=\"predict\"\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 420, in load\n    **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 350, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'transform/transform/inputs/fnlwgt' with dtype int64 and shape [?,1]\n\t [[node transform/transform/inputs/fnlwgt (defined at <ipython-input-22-01faacbd3703>:9) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'transform/transform/inputs/fnlwgt' with dtype int64 and shape [?,1]\n\t [[{{node transform/transform/inputs/fnlwgt}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-01faacbd3703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/predictor/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'transform/transform/inputs/fnlwgt' with dtype int64 and shape [?,1]\n\t [[node transform/transform/inputs/fnlwgt (defined at <ipython-input-22-01faacbd3703>:9) ]]\n\nCaused by op 'transform/transform/inputs/fnlwgt', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-01faacbd3703>\", line 9, in <module>\n    signature_def_key=\"predict\"\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 420, in load\n    **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 350, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'transform/transform/inputs/fnlwgt' with dtype int64 and shape [?,1]\n\t [[node transform/transform/inputs/fnlwgt (defined at <ipython-input-22-01faacbd3703>:9) ]]\n"
     ]
    }
   ],
   "source": [
    "export_dir = os.path.join(model_dir, 'export')\n",
    "tf.gfile.ListDirectory(export_dir)[-1]\n",
    "saved_model_dir = os.path.join(export_dir, tf.gfile.ListDirectory(export_dir)[-1])\n",
    "print(saved_model_dir)\n",
    "print()\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = saved_model_dir,\n",
    "    signature_def_key=\"predict\"\n",
    ")\n",
    "\n",
    "input = {\n",
    "        'age': [34.0],\n",
    "        'workclass': ['Private'],\n",
    "        'education': ['Doctorate'],\n",
    "        'education_num': [10.0],\n",
    "        'marital_status': ['Married-civ-spouse'],\n",
    "        'occupation': ['Prof-specialty'],\n",
    "        'relationship': ['Husband'],\n",
    "        'race': ['White'],\n",
    "        'gender': ['Male'],\n",
    "        'capital_gain': [0.0], \n",
    "        'capital_loss': [0.0], \n",
    "        'hours_per_week': [40.0],\n",
    "        'native_country':['Mexico']\n",
    "}\n",
    "\n",
    "print(input)\n",
    "print()\n",
    "output = predictor_fn(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Deploy model to Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#MODEL_NAME=\"census\"\n",
    "#MODEL_VERSION=\"v1\"\n",
    "#MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/census/dnn_classifier/export/exporter | tail -1)\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "#gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Export evaluation saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],\n",
    "                   [0], [0], [0], [''], ['']]\n",
    "\n",
    "def make_eval_input_receiver_fn():\n",
    "  receiver_tensors = {'examples': tf.placeholder(dtype=tf.string, shape=[None])}\n",
    "  columns = tf.decode_csv(receiver_tensors['examples'], record_defaults=HEADER_DEFAULTS)\n",
    "  features = dict(zip(HEADER, columns))\n",
    "  print(features)\n",
    "\n",
    "  for feature_name in features:\n",
    "    if features[feature_name].dtype == tf.int32:\n",
    "      features[feature_name] = tf.cast(features[feature_name], tf.int64)\n",
    "    features[feature_name] = tf.reshape(features[feature_name], (-1, 1))\n",
    "\n",
    "  transformed_features = transform_output.transform_raw_features(features)\n",
    "  features.update(transformed_features)\n",
    "\n",
    "  return tfma.export.EvalInputReceiver(\n",
    "    features=features,\n",
    "    receiver_tensors=receiver_tensors,\n",
    "    labels=features[TARGET_FEATURE_NAME]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'education': <tf.Tensor 'DecodeCSV:3' shape=(?,) dtype=string>, 'hours_per_week': <tf.Tensor 'DecodeCSV:12' shape=(?,) dtype=int32>, 'race': <tf.Tensor 'DecodeCSV:8' shape=(?,) dtype=string>, 'capital_loss': <tf.Tensor 'DecodeCSV:11' shape=(?,) dtype=int32>, 'education_num': <tf.Tensor 'DecodeCSV:4' shape=(?,) dtype=int32>, 'workclass': <tf.Tensor 'DecodeCSV:1' shape=(?,) dtype=string>, 'native_country': <tf.Tensor 'DecodeCSV:13' shape=(?,) dtype=string>, 'age': <tf.Tensor 'DecodeCSV:0' shape=(?,) dtype=int32>, 'gender': <tf.Tensor 'DecodeCSV:9' shape=(?,) dtype=string>, 'marital_status': <tf.Tensor 'DecodeCSV:5' shape=(?,) dtype=string>, 'income_bracket': <tf.Tensor 'DecodeCSV:14' shape=(?,) dtype=string>, 'occupation': <tf.Tensor 'DecodeCSV:6' shape=(?,) dtype=string>, 'capital_gain': <tf.Tensor 'DecodeCSV:10' shape=(?,) dtype=int32>, 'relationship': <tf.Tensor 'DecodeCSV:7' shape=(?,) dtype=string>, 'fnlwgt': <tf.Tensor 'DecodeCSV:2' shape=(?,) dtype=int32>}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected inputs to transform: {'fnlwgt'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e53d2acddaff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mexport_dir_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_model_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0meval_input_receiver_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_eval_input_receiver_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_model_analysis/util.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m                       (fn.__name__, kwargs.keys()))\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs_to_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_model_analysis/eval_saved_model/export.py\u001b[0m in \u001b[0;36mexport_eval_savedmodel\u001b[0;34m(estimator, export_dir_base, eval_input_receiver_fn, serving_input_receiver_fn, assets_extra, checkpoint_path)\u001b[0m\n\u001b[1;32m    467\u001b[0m       },\n\u001b[1;32m    468\u001b[0m       \u001b[0massets_extra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massets_extra\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       checkpoint_path=checkpoint_path)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/export.py\u001b[0m in \u001b[0;36mexport_all_saved_models\u001b[0;34m(estimator, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path)\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0massets_extra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massets_extra\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m       checkpoint_path=checkpoint_path)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mexperimental_export_all_saved_models\u001b[0;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path)\u001b[0m\n\u001b[1;32m    820\u001b[0m         self._add_meta_graph_for_mode(\n\u001b[1;32m    821\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_receiver_fn_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m             save_variables, mode=model_fn_lib.ModeKeys.EVAL)\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0msave_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_receiver_fn_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_add_meta_graph_for_mode\u001b[0;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m       \u001b[0minput_receiver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_receiver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0;31m# Call the model_fn and collect the export_outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-50c17e8775fd>\u001b[0m in \u001b[0;36mmake_eval_input_receiver_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mtransformed_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_raw_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_transform/output_wrapper.py\u001b[0m in \u001b[0;36mtransform_raw_features\u001b[0;34m(self, raw_features)\u001b[0m\n\u001b[1;32m    130\u001b[0m     _, transformed_features = (\n\u001b[1;32m    131\u001b[0m         saved_transform_io.partially_apply_saved_transform_internal(\n\u001b[0;32m--> 132\u001b[0;31m             self.transform_savedmodel_dir, raw_features))\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformed_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_transform/saved/saved_transform_io.py\u001b[0m in \u001b[0;36mpartially_apply_saved_transform_internal\u001b[0;34m(saved_model_dir, logical_input_map, tensor_replacement_map)\u001b[0m\n\u001b[1;32m    368\u001b[0m   \"\"\"\n\u001b[1;32m    369\u001b[0m   unbound_inputs, outputs, _ = _partially_apply_saved_transform_impl(\n\u001b[0;32m--> 370\u001b[0;31m       saved_model_dir, logical_input_map, tensor_replacement_map)\n\u001b[0m\u001b[1;32m    371\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0munbound_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_transform/saved/saved_transform_io.py\u001b[0m in \u001b[0;36m_partially_apply_saved_transform_impl\u001b[0;34m(saved_model_dir, logical_input_map, tensor_replacement_map, fetch_tensor_names)\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0munexpected_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     raise ValueError('Unexpected inputs '\n\u001b[0;32m--> 173\u001b[0;31m                      'to transform: {}'.format(unexpected_inputs))\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0;31m# Create a map from tensor names in the graph to be imported, to the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected inputs to transform: {'fnlwgt'}"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "eval_model_dir = os.path.join(model_dir, \"export/evaluate\")\n",
    "if tf.gfile.Exists(eval_model_dir):\n",
    "    tf.gfile.DeleteRecursively(eval_model_dir)\n",
    "\n",
    "tfma.export.export_eval_savedmodel(\n",
    "        estimator=estimator,\n",
    "        export_dir_base=eval_model_dir,\n",
    "        eval_input_receiver_fn=make_eval_input_receiver_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gsi_Hsh89Cl7"
   },
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fOWx1yI9Dyn"
   },
   "source": [
    "Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "---\n",
    "This is not an official Google product. The sample code provided for educational purposes only.\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02-tfx_end_to_end",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
